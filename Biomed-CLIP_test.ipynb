{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install open_clip_torch transformers matplotlib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import open_clip\n",
    "\n",
    "model, preprocess_train, preprocess_val = open_clip.create_model_and_transforms('hf-hub:microsoft/BiomedCLIP-PubMedBERT_256-vit_base_patch16_224')\n",
    "tokenizer = open_clip.get_tokenizer('hf-hub:microsoft/BiomedCLIP-PubMedBERT_256-vit_base_patch16_224')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from huggingface_hub import snapshot_download\n",
    "snapshot_download(\"microsoft/BiomedCLIP-PubMedBERT_256-vit_base_patch16_224\", local_dir=\"biomed-clip-share\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Import Data "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import random \n",
    "\n",
    "def get_all_files(directory):\n",
    "    all_files = []\n",
    "    \n",
    "    # Iterate over all the directories and files within the given directory\n",
    "    for root, directories, files in os.walk(directory):\n",
    "        for file in files:\n",
    "            file_path = os.path.join(root, file)\n",
    "            all_files.append(file_path)\n",
    "    \n",
    "    return all_files\n",
    "\n",
    "def get_random_file(directory):\n",
    "    all_files = get_all_files(directory)\n",
    "    return random.choice(all_files)\n",
    "\n",
    "directory = 'RIM-ONE_DL_images/partitioned_randomly/training_set'\n",
    "\n",
    "files = get_all_files(directory)\n",
    "random.shuffle(files)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import glob\n",
    "from collections import OrderedDict\n",
    "\n",
    "import torch\n",
    "from PIL import Image\n",
    "import open_clip\n",
    "\n",
    "\n",
    "\n",
    "dataset_path = 'biomed-clip-share/example_data/biomed_image_classification_example_data'\n",
    "template = 'this is a '\n",
    "labels = [\n",
    "    'glaucoma fundus photo',\n",
    "    'normal fundus photo'\n",
    "]\n",
    "\n",
    "### TODO: Change this to the glaucoma images after testing on orig images\n",
    "test_imgs = glob.glob(dataset_path + '/*')\n",
    "\n",
    "device = torch.device('cuda') if torch.cuda.is_available() else torch.device('cpu')\n",
    "model.to(device)\n",
    "model.eval()\n",
    "\n",
    "context_length = 256\n",
    "\n",
    "images = torch.stack([preprocess_val(Image.open(img)) for img in test_imgs]).to(device)\n",
    "texts = tokenizer([template + l for l in labels], context_length=context_length).to(device)\n",
    "with torch.no_grad():\n",
    "    image_features, text_features, logit_scale = model(images, texts)\n",
    "\n",
    "    logits = (logit_scale * image_features @ text_features.t()).detach().softmax(dim=-1)\n",
    "    sorted_indices = torch.argsort(logits, dim=-1, descending=True)\n",
    "\n",
    "    logits = logits.cpu().numpy()\n",
    "    sorted_indices = sorted_indices.cpu().numpy()\n",
    "\n",
    "top_k = -1\n",
    "\n",
    "for i, img in enumerate(test_imgs):\n",
    "    pred = labels[sorted_indices[i][0]]\n",
    "\n",
    "    top_k = len(labels) if top_k == -1 else top_k\n",
    "    print(img.split('/')[-1] + ':')\n",
    "    for j in range(top_k):\n",
    "        jth_index = sorted_indices[i][j]\n",
    "        print(f'{labels[jth_index]}: {logits[i][jth_index]}')\n",
    "    print('\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "def plot_images_with_metadata(images, metadata):\n",
    "    num_images = len(images)\n",
    "    fig, axes = plt.subplots(nrows=num_images, ncols=1, figsize=(5, 5 * num_images))\n",
    "\n",
    "    for i, (img_path, metadata) in enumerate(zip(images, metadata)):\n",
    "        img = Image.open(img_path)\n",
    "        ax = axes[i]\n",
    "        ax.imshow(img)\n",
    "        ax.axis('off')\n",
    "        ax.set_title(f\"{metadata['filename']}\\n{metadata['top_probs']}\", fontsize=14)\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "metadata_list = []\n",
    "\n",
    "top_k = 3\n",
    "for i, img in enumerate(test_imgs):\n",
    "    pred = labels[sorted_indices[i][0]]\n",
    "    img_name = img.split('/')[-1]\n",
    "\n",
    "    top_probs = []\n",
    "    top_k = len(labels) if top_k == -1 else top_k\n",
    "    for j in range(top_k):\n",
    "        jth_index = sorted_indices[i][j]\n",
    "        top_probs.append(f\"{labels[jth_index]}: {logits[i][jth_index] * 100:.1f}\")\n",
    "\n",
    "    metadata = {'filename': img_name, 'top_probs': '\\n'.join(top_probs)}\n",
    "    metadata_list.append(metadata)\n",
    "\n",
    "plot_images_with_metadata(test_imgs, metadata_list)"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
