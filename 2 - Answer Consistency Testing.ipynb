{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e2afdb06-51c7-4344-919c-35c1c68dbf6a",
   "metadata": {},
   "source": [
    "# MiniGPT-4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d6af2beb-8d85-472b-ba47-8a27f03f7e8b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/jupyter/opthollm/MiniGPT-4\n"
     ]
    }
   ],
   "source": [
    "%cd MiniGPT-4"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "84c0e340-4138-4ca9-9d05-3629ad0e66a5",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ffa89ce9-016c-4138-b326-7f4c1c452a28",
   "metadata": {},
   "outputs": [],
   "source": [
    "#@title Import\n",
    "import argparse\n",
    "import os\n",
    "import random\n",
    "\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.backends.cudnn as cudnn\n",
    "import gradio as gr\n",
    "\n",
    "from minigpt4.common.config import Config\n",
    "from minigpt4.common.dist_utils import get_rank\n",
    "from minigpt4.common.registry import registry\n",
    "from minigpt4.conversation.multi_img_conversation import Chat, CONV_VISION\n",
    "\n",
    "# imports modules for registration\n",
    "from minigpt4.datasets.builders import *\n",
    "from minigpt4.models import *\n",
    "from minigpt4.processors import *\n",
    "from minigpt4.runners import *\n",
    "from minigpt4.tasks import *\n",
    "import os\n",
    "\n",
    "import argparse as argparse"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a2f979de-e8ca-46c7-a320-112ddc9cd427",
   "metadata": {},
   "source": [
    "### Helper Methods"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "9e7b0b91-0e31-4233-a9f5-ac7b8d1463a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "#@title Helper Methods\n",
    "def parse_args():\n",
    "    parser = argparse.ArgumentParser(description=\"Demo\")\n",
    "    parser.add_argument(\"--cfg-path\", required=True, help=\"path to configuration file.\")\n",
    "    parser.add_argument(\"--gpu-id\", type=int, default=0, help=\"specify the gpu to load the model.\")\n",
    "    parser.add_argument(\"--num-beams\", type=int, default=2, help=\"specify the gpu to load the model.\")\n",
    "    parser.add_argument(\"--temperature\", type=int, default=0.9, help=\"specify the gpu to load the model.\")\n",
    "    parser.add_argument(\"--english\", type=bool, default=True, help=\"chinese or english\")\n",
    "    parser.add_argument(\"--prompt-en\", type=str, default=\"can you describe the current picture?\", help=\"Can you describe the current picture?\")\n",
    "    parser.add_argument(\"--prompt-zh\", type=str, default=\"你能描述一下当前的图片？\", help=\"Can you describe the current picture?\")\n",
    "    parser.add_argument(\n",
    "        \"--options\",\n",
    "        nargs=\"+\",\n",
    "        help=\"override some settings in the used config, the key-value pair \"\n",
    "        \"in xxx=yyy format will be merged into config file (deprecate), \"\n",
    "        \"change to --cfg-options instead.\",\n",
    "    )\n",
    "    args = parser.parse_args()\n",
    "    return args\n",
    "\n",
    "\n",
    "def setup_seeds(config):\n",
    "    seed = config.run_cfg.seed + get_rank()\n",
    "\n",
    "    random.seed(seed)\n",
    "    np.random.seed(seed)\n",
    "    torch.manual_seed(seed)\n",
    "\n",
    "    cudnn.benchmark = False\n",
    "    cudnn.deterministic = True\n",
    "\n",
    "def ask_model(chat_state, image, prompt, img_list):\n",
    "    if image is not None: \n",
    "        chat_state.upload_img(image, chat_state, img_list)\n",
    "    chat_state.ask(prompt, chat_state)\n",
    "    llm_message = chat_state.answer(\n",
    "        conv=chat_state,\n",
    "        img_list=img_list,\n",
    "        num_beams=args.num_beams,\n",
    "        temperature=args.temperature,\n",
    "        max_new_tokens=300,\n",
    "        max_length=2000\n",
    "    )[0]\n",
    "    return llm_message"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d8309d42-370c-4216-a6f4-19ff74f27c8b",
   "metadata": {},
   "source": [
    "### Initialize Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "ca5600ee-fa40-49a8-8bed-69ed8ddeb6bd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initializing Chat\n",
      "Loading VIT\n",
      "Loading VIT Done\n",
      "Loading Q-Former\n",
      "Loading Q-Former Done\n",
      "Loading LLAMA\n",
      "\n",
      "===================================BUG REPORT===================================\n",
      "Welcome to bitsandbytes. For bug reports, please submit your error trace to: https://github.com/TimDettmers/bitsandbytes/issues\n",
      "================================================================================\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7fd680c3a54a4364bc39d8df9f11cb42",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/3 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading LLAMA Done\n",
      "Load 4 training prompts\n",
      "Prompt Example \n",
      "###Human: <Img><ImageHere></Img> Describe this image in detail. ###Assistant: \n",
      "Load BLIP2-LLM Checkpoint: pretrained_minigpt4.pth\n",
      "Initialization Finished\n",
      "Intializing Test\n"
     ]
    }
   ],
   "source": [
    "print('Initializing Chat')\n",
    "#args = parse_args()\n",
    "#args = preset_args\n",
    "args = argparse.Namespace(cfg_path='eval_configs/minigpt4_eval.yaml', gpu_id=0, num_beams=2, temperature=0.9, english=True, prompt_en='can you describe the current picture?', prompt_zh='你能描述一下当前的图片？', options=None)\n",
    "cfg = Config(args)\n",
    "\n",
    "model_config = cfg.model_cfg\n",
    "model_config.device_8bit = args.gpu_id\n",
    "model_cls = registry.get_model_class(model_config.arch)\n",
    "model = model_cls.from_config(model_config).to('cuda:{}'.format(args.gpu_id))\n",
    "\n",
    "vis_processor_cfg = cfg.datasets_cfg.cc_sbu_align.vis_processor.train\n",
    "vis_processor = registry.get_processor_class(vis_processor_cfg.name).from_config(vis_processor_cfg)\n",
    "chat = Chat(model, vis_processor, device='cuda:{}'.format(args.gpu_id))\n",
    "print('Initialization Finished')\n",
    "\n",
    "print('Intializing Test')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "baee9e17-5a23-47dc-ac38-d5096efe027b",
   "metadata": {},
   "source": [
    "## Testing Example Image Consistency"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "7e6c999b-2db6-4dc8-8e92-00b5891163aa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The image shows a page from a manga or comic book. The panel depicts a fight scene between two characters, one with a serious expression and the other with a smirk on his face. The background is a cityscape with buildings and cars in the distance. The panel is drawn in a realistic style with attention to detail in the characters'faces and clothing. The panel is in black and white, with the characters and background in shading.\n",
      "The image shows a page from a manga or anime comic book. The panel depicts a fight scene between two characters, one of whom is a dragon ball z character. The panel shows the characters in action, with one character delivering a punch to the other character's face. The panel is drawn in a manga or anime style, with exaggerated facial expressions and dynamic action lines. The panel is in black and white, with the characters and background in solid black and the action lines in white. The panel is part of a larger comic book or manga story, and the scene depicted in the panel is part of the plot or storyline.</s>\n",
      "The image shows a page from a manga or anime comic book. The panel depicts a fight scene between two characters, one of whom is a super saiyan and the other is a normal human. The super saiyan is shown with a determined expression, while the human is shown with a scared expression. The background is a cityscape with buildings and smoke in the distance. The panel is drawn in a manga style with bold lines and exaggerated facial expressions.\n",
      "The image shows a page from a manga or anime comic book. The panel depicts a fight scene between two characters, one of whom is a super saiyan, and the other is a normal human. The super saiyan is shown with a determined expression, while the human is shown with a scared expression. The panel is drawn in a dynamic and action-packed style, with the characters shown in various poses, including a flying kick and a punch. The panel is in black and white, with the characters and background depicted in shading and lines.\n",
      "The image shows a page from a manga or anime comic book. The panel depicts a fight scene between two characters, one of whom is a dragon ball z character. The panel shows the characters in action, with one character punching the other. The panel is in black and white, with the characters and background in shades of gray. The panel is drawn in a manga or anime style, with exaggerated proportions and expressions on the characters'faces. The panel is part of a larger story or series, and the characters and their actions are consistent with the story'splot and themes.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[\"The image shows a page from a manga or comic book. The panel depicts a fight scene between two characters, one with a serious expression and the other with a smirk on his face. The background is a cityscape with buildings and cars in the distance. The panel is drawn in a realistic style with attention to detail in the characters'faces and clothing. The panel is in black and white, with the characters and background in shading.\",\n",
       " \"The image shows a page from a manga or anime comic book. The panel depicts a fight scene between two characters, one of whom is a dragon ball z character. The panel shows the characters in action, with one character delivering a punch to the other character's face. The panel is drawn in a manga or anime style, with exaggerated facial expressions and dynamic action lines. The panel is in black and white, with the characters and background in solid black and the action lines in white. The panel is part of a larger comic book or manga story, and the scene depicted in the panel is part of the plot or storyline.</s>\",\n",
       " 'The image shows a page from a manga or anime comic book. The panel depicts a fight scene between two characters, one of whom is a super saiyan and the other is a normal human. The super saiyan is shown with a determined expression, while the human is shown with a scared expression. The background is a cityscape with buildings and smoke in the distance. The panel is drawn in a manga style with bold lines and exaggerated facial expressions.',\n",
       " 'The image shows a page from a manga or anime comic book. The panel depicts a fight scene between two characters, one of whom is a super saiyan, and the other is a normal human. The super saiyan is shown with a determined expression, while the human is shown with a scared expression. The panel is drawn in a dynamic and action-packed style, with the characters shown in various poses, including a flying kick and a punch. The panel is in black and white, with the characters and background depicted in shading and lines.',\n",
       " \"The image shows a page from a manga or anime comic book. The panel depicts a fight scene between two characters, one of whom is a dragon ball z character. The panel shows the characters in action, with one character punching the other. The panel is in black and white, with the characters and background in shades of gray. The panel is drawn in a manga or anime style, with exaggerated proportions and expressions on the characters'faces. The panel is part of a larger story or series, and the characters and their actions are consistent with the story'splot and themes.\"]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Select the example image file path \n",
    "\n",
    "minigpt4_example_img_path = 'StepTwoImageConsistencyImages/people_1.png' \n",
    "minigpt4_example_img_results = []\n",
    "\n",
    "prompt = \"Please describe the image\"\n",
    "chat_state = CONV_VISION.copy()\n",
    "\n",
    "for i in range(5):\n",
    "    chat_state = CONV_VISION.copy()\n",
    "    llm_message = ask_model(chat_state, minigpt4_example_img_path, prompt, [])\n",
    "    print(llm_message)\n",
    "    minigpt4_example_img_results.append(llm_message)\n",
    "   \n",
    "minigpt4_example_img_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "ee4d33de-99d4-464f-b8b5-66b3af15db89",
   "metadata": {},
   "outputs": [],
   "source": [
    "# save results \n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "minigpt4_example_img_results_df = pd.DataFrame(minigpt4_example_img_results)\n",
    "minigpt4_example_img_results_df.to_csv('minigpt4_example_img_consistency_test_results.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "16e46591-fb5b-4af9-bc48-7744cc4a2ee7",
   "metadata": {},
   "source": [
    "## Testing Eye Image Consistency "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "e0a62ddb-d8f5-4157-9043-db3c12366d5b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Based on the provided image, it appears to be a normal eye with no signs of glaucoma. The optic disc appears to be symmetrical and the cup-to-disc ratio is within normal limits. The neuroretinal rim appears intact and there are no signs of notching or defects. The blood vessels appear normal and there are no signs of vascular changes. Overall, the image appears to be normal.\n",
      "Based on the provided image, it appears to be a normal eye with no signs of glaucoma. The optic disc appears to be symmetrical and the cup-to-disc ratio is within normal limits. The neuroretinal rim appears to be intact and there are no signs of notching or rim thinning. The blood vessels appear to be normal and there are no signs of vascular changes. Overall, the image appears to be normal.\n",
      "Based on the provided image, it appears to be a normal eye with no signs of glaucoma. The optic disc appears to be symmetrical and the cup-to-disc ratio is within normal limits. The neuroretinal rim appears intact and there are no notches or defects visible. The blood vessels appear to be normal as well.\n",
      "Based on the provided image, it appears to be a normal eye with no signs of glaucoma. The optic disc appears to be symmetrical and the cup-to-disc ratio is within normal limits. The neuroretinal rim appears intact and there are no signs of notching or defects. The blood vessels appear to be normal and there are no signs of vascular changes. Overall, the image appears to be normal.\n",
      "Based on the provided image, it appears to be a normal eye with no signs of glaucoma. The optic disc appears to be of normal size and shape, and there are no notches or hemorrhages visible in the neuroretinal rim. The blood vessels appear to be normal as well. Therefore, the diagnosis is normal.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['Based on the provided image, it appears to be a normal eye with no signs of glaucoma. The optic disc appears to be symmetrical and the cup-to-disc ratio is within normal limits. The neuroretinal rim appears intact and there are no signs of notching or defects. The blood vessels appear normal and there are no signs of vascular changes. Overall, the image appears to be normal.',\n",
       " 'Based on the provided image, it appears to be a normal eye with no signs of glaucoma. The optic disc appears to be symmetrical and the cup-to-disc ratio is within normal limits. The neuroretinal rim appears to be intact and there are no signs of notching or rim thinning. The blood vessels appear to be normal and there are no signs of vascular changes. Overall, the image appears to be normal.',\n",
       " 'Based on the provided image, it appears to be a normal eye with no signs of glaucoma. The optic disc appears to be symmetrical and the cup-to-disc ratio is within normal limits. The neuroretinal rim appears intact and there are no notches or defects visible. The blood vessels appear to be normal as well.',\n",
       " 'Based on the provided image, it appears to be a normal eye with no signs of glaucoma. The optic disc appears to be symmetrical and the cup-to-disc ratio is within normal limits. The neuroretinal rim appears intact and there are no signs of notching or defects. The blood vessels appear to be normal and there are no signs of vascular changes. Overall, the image appears to be normal.',\n",
       " 'Based on the provided image, it appears to be a normal eye with no signs of glaucoma. The optic disc appears to be of normal size and shape, and there are no notches or hemorrhages visible in the neuroretinal rim. The blood vessels appear to be normal as well. Therefore, the diagnosis is normal.']"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "minigpt4_eye_img_path = 'StepTwoImageConsistencyImages/r1_Im069.png' \n",
    "minigpt4_eye_img_results = []\n",
    "\n",
    "prompt = \"Please diagnose the image as either glaucomatous or normal\"\n",
    "\n",
    "for i in range(5):\n",
    "    chat_state = CONV_VISION.copy()\n",
    "    llm_message = ask_model(chat_state, minigpt4_eye_img_path, prompt, [])\n",
    "    print(llm_message)\n",
    "    minigpt4_eye_img_results.append(llm_message)\n",
    "    \n",
    "minigpt4_eye_img_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "6ff747af-13f1-4710-8c94-a58ceec99440",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Based on the provided image, it appears to be ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Based on the provided image, it appears to be ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Based on the provided image, it appears to be ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Based on the provided image, it appears to be ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Based on the provided image, it appears to be ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                   0\n",
       "0  Based on the provided image, it appears to be ...\n",
       "1  Based on the provided image, it appears to be ...\n",
       "2  Based on the provided image, it appears to be ...\n",
       "3  Based on the provided image, it appears to be ...\n",
       "4  Based on the provided image, it appears to be ..."
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# save results \n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "minigpt4_eye_img_results_df = pd.DataFrame(minigpt4_eye_img_results)\n",
    "minigpt4_eye_img_results_df.to_csv('minigpt4_eye_img_consistency_test_results.csv')\n",
    "minigpt4_eye_img_results_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "45fb7df3-ef4e-49b5-99ad-8af91b211c94",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "environment": {
   "kernel": "python3",
   "name": "pytorch-gpu.1-13.m109",
   "type": "gcloud",
   "uri": "gcr.io/deeplearning-platform-release/pytorch-gpu.1-13:m109"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
