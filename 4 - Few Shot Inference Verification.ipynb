{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "eb8d6137-3120-4f23-9973-a5ec31ab89ba",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/jupyter/opthollm/MiniGPT-4\n"
     ]
    }
   ],
   "source": [
    "%cd MiniGPT-4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "fc8eae6f-c8b0-4d2e-bafb-c604338de999",
   "metadata": {},
   "outputs": [],
   "source": [
    "#@title Import\n",
    "import argparse\n",
    "import os\n",
    "import random\n",
    "\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.backends.cudnn as cudnn\n",
    "import gradio as gr\n",
    "\n",
    "from minigpt4.common.config import Config\n",
    "from minigpt4.common.dist_utils import get_rank\n",
    "from minigpt4.common.registry import registry\n",
    "from minigpt4.conversation.multi_img_conversation import Chat, CONV_VISION\n",
    "\n",
    "# imports modules for registration\n",
    "from minigpt4.datasets.builders import *\n",
    "from minigpt4.models import *\n",
    "from minigpt4.processors import *\n",
    "from minigpt4.runners import *\n",
    "from minigpt4.tasks import *\n",
    "import os\n",
    "\n",
    "import argparse as argparse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "bb0b738f-deaa-4f5a-9065-3a163eeda4bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "#@title Helper Methods\n",
    "def parse_args():\n",
    "    parser = argparse.ArgumentParser(description=\"Demo\")\n",
    "    parser.add_argument(\"--cfg-path\", required=True, help=\"path to configuration file.\")\n",
    "    parser.add_argument(\"--gpu-id\", type=int, default=0, help=\"specify the gpu to load the model.\")\n",
    "    parser.add_argument(\"--num-beams\", type=int, default=2, help=\"specify the gpu to load the model.\")\n",
    "    parser.add_argument(\"--temperature\", type=int, default=0.9, help=\"specify the gpu to load the model.\")\n",
    "    parser.add_argument(\"--english\", type=bool, default=True, help=\"chinese or english\")\n",
    "    parser.add_argument(\"--prompt-en\", type=str, default=\"can you describe the current picture?\", help=\"Can you describe the current picture?\")\n",
    "    parser.add_argument(\"--prompt-zh\", type=str, default=\"你能描述一下当前的图片？\", help=\"Can you describe the current picture?\")\n",
    "    parser.add_argument(\n",
    "        \"--options\",\n",
    "        nargs=\"+\",\n",
    "        help=\"override some settings in the used config, the key-value pair \"\n",
    "        \"in xxx=yyy format will be merged into config file (deprecate), \"\n",
    "        \"change to --cfg-options instead.\",\n",
    "    )\n",
    "    args = parser.parse_args()\n",
    "    return args\n",
    "\n",
    "\n",
    "def setup_seeds(config):\n",
    "    seed = config.run_cfg.seed + get_rank()\n",
    "\n",
    "    random.seed(seed)\n",
    "    np.random.seed(seed)\n",
    "    torch.manual_seed(seed)\n",
    "\n",
    "    cudnn.benchmark = False\n",
    "    cudnn.deterministic = True\n",
    "\n",
    "def ask_model(chat_state, image, prompt, img_list):\n",
    "    if image is not None:\n",
    "        chat.upload_img(image, chat_state, img_list)\n",
    "    chat.ask(prompt, chat_state)\n",
    "    llm_message = chat.answer(\n",
    "        conv=chat_state,\n",
    "        img_list=img_list,\n",
    "        num_beams=args.num_beams,\n",
    "        temperature=args.temperature,\n",
    "        max_new_tokens=300,\n",
    "        max_length=2000\n",
    "    )[0]\n",
    "    return llm_message"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "27a764e0-a5ab-45bc-8aaa-bdae5aa7a60e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initializing Chat\n",
      "Loading VIT\n",
      "Loading VIT Done\n",
      "Loading Q-Former\n",
      "Loading Q-Former Done\n",
      "Loading LLAMA\n",
      "\n",
      "===================================BUG REPORT===================================\n",
      "Welcome to bitsandbytes. For bug reports, please submit your error trace to: https://github.com/TimDettmers/bitsandbytes/issues\n",
      "================================================================================\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1ae32ae34ca34333990ac55542b7d6a2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/3 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading LLAMA Done\n",
      "Load 4 training prompts\n",
      "Prompt Example \n",
      "###Human: <Img><ImageHere></Img> Describe this image in detail. ###Assistant: \n",
      "Load BLIP2-LLM Checkpoint: pretrained_minigpt4.pth\n",
      "Initialization Finished\n",
      "Intializing Test\n"
     ]
    }
   ],
   "source": [
    "print('Initializing Chat')\n",
    "#args = parse_args()\n",
    "#args = preset_args\n",
    "args = argparse.Namespace(cfg_path='eval_configs/minigpt4_eval.yaml', gpu_id=0, num_beams=2, temperature=0.9, english=True, prompt_en='can you describe the current picture?', prompt_zh='你能描述一下当前的图片？', options=None)\n",
    "cfg = Config(args)\n",
    "\n",
    "model_config = cfg.model_cfg\n",
    "model_config.device_8bit = args.gpu_id\n",
    "model_cls = registry.get_model_class(model_config.arch)\n",
    "model = model_cls.from_config(model_config).to('cuda:{}'.format(args.gpu_id))\n",
    "\n",
    "vis_processor_cfg = cfg.datasets_cfg.cc_sbu_align.vis_processor.train\n",
    "vis_processor = registry.get_processor_class(vis_processor_cfg.name).from_config(vis_processor_cfg)\n",
    "chat = Chat(model, vis_processor, device='cuda:{}'.format(args.gpu_id))\n",
    "print('Initialization Finished')\n",
    "\n",
    "print('Intializing Test')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "7bc4e457-d7ca-441c-87d7-3ec2c80ce01d",
   "metadata": {},
   "outputs": [],
   "source": [
    "minigpt4_inference_data = {\"level\" : [],\n",
    "                           \"prompt\" : [],\n",
    "                           \"llm_message\" : []}\n",
    "\n",
    "prompt1 = \"The cafeteria had 23 apples. If they used 20 to make lunch and bought 6 more, how many apples do they have?\"\n",
    "prompt2 = \"\"\"Q: Roger has 5 tennis balls. He buys 2 more cans of tennis balls. Each can has 3 tennis balls. How many tennis balls does he have now?\n",
    "A: The answer is 11.\n",
    "Q: The cafeteria had 23 apples. If they used 20 to make lunch and bought 6 more, how many apples do they have?\"\"\"\n",
    "prompt3 = \"\"\"Q: The cafeteria had 23 apples. If they used 20 to make lunch and bought 6 more, how many apples do they have?\n",
    "Q: Roger has 5 tennis balls. He buys 2 more cans of tennis balls. Each can has 3 tennis balls. How many tennis balls does he have now?\n",
    "A: Roger started with 5 balls. 2 cans of 3 tennis balls each is 6 tennis balls. 5 + 6 = 11. The answer is 11.\n",
    "Q: The cafeteria had 23 apples. If they used 20 to make lunch and bought 6 more, how many apples do they have?\"\"\"\n",
    "\n",
    "prompts = [prompt1, prompt2, prompt3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "90c9d803-c3c2-4811-9843-f06a83057e08",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The cafeteria had 23 apples to begin with. They used 20 of those apples to make lunch, so they have 23 - 20 = 3 apples left over. They then bought 6 more apples, so they now have a total of 3 + 6 = 9 apples. Therefore, the cafeteria has 9 apples in total.\n",
      "A: The answer is 29 apples.\n",
      "A: The cafeteria started with 23 apples. They used 20 apples to make lunch, so they have 23 - 20 = 3 apples left. Then, they bought 6 more apples, so they now have 3 + 6 = 9 apples. Therefore, the cafeteria has 9 apples now.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'level': [0, 1, 2],\n",
       " 'prompt': ['The cafeteria had 23 apples. If they used 20 to make lunch and bought 6 more, how many apples do they have?',\n",
       "  'Q: Roger has 5 tennis balls. He buys 2 more cans of tennis balls. Each can has 3 tennis balls. How many tennis balls does he have now?\\nA: The answer is 11.\\nQ: The cafeteria had 23 apples. If they used 20 to make lunch and bought 6 more, how many apples do they have?',\n",
       "  'Q: The cafeteria had 23 apples. If they used 20 to make lunch and bought 6 more, how many apples do they have?\\nQ: Roger has 5 tennis balls. He buys 2 more cans of tennis balls. Each can has 3 tennis balls. How many tennis balls does he have now?\\nA: Roger started with 5 balls. 2 cans of 3 tennis balls each is 6 tennis balls. 5 + 6 = 11. The answer is 11.\\nQ: The cafeteria had 23 apples. If they used 20 to make lunch and bought 6 more, how many apples do they have?'],\n",
       " 'llm_message': ['The cafeteria had 23 apples to begin with. They used 20 of those apples to make lunch, so they have 23 - 20 = 3 apples left over. They then bought 6 more apples, so they now have a total of 3 + 6 = 9 apples. Therefore, the cafeteria has 9 apples in total.',\n",
       "  'A: The answer is 29 apples.',\n",
       "  'A: The cafeteria started with 23 apples. They used 20 apples to make lunch, so they have 23 - 20 = 3 apples left. Then, they bought 6 more apples, so they now have 3 + 6 = 9 apples. Therefore, the cafeteria has 9 apples now.']}"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "for num, prompt in enumerate(prompts):\n",
    "    chat_state = CONV_VISION.copy()\n",
    "    llm_message = ask_model(chat_state, None, prompt, [])\n",
    "    print(llm_message)\n",
    "    minigpt4_inference_data[\"level\"].append(num)\n",
    "    minigpt4_inference_data[\"prompt\"].append(prompt)\n",
    "    minigpt4_inference_data[\"llm_message\"].append(llm_message)\n",
    "    \n",
    "minigpt4_inference_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "144669a2-989e-441b-88ec-4ddde22ccdd6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>level</th>\n",
       "      <th>prompt</th>\n",
       "      <th>llm_message</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>The cafeteria had 23 apples. If they used 20 t...</td>\n",
       "      <td>The cafeteria had 23 apples to begin with. The...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>Q: Roger has 5 tennis balls. He buys 2 more ca...</td>\n",
       "      <td>A: The answer is 29 apples.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>Q: The cafeteria had 23 apples. If they used 2...</td>\n",
       "      <td>A: The cafeteria started with 23 apples. They ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   level                                             prompt  \\\n",
       "0      0  The cafeteria had 23 apples. If they used 20 t...   \n",
       "1      1  Q: Roger has 5 tennis balls. He buys 2 more ca...   \n",
       "2      2  Q: The cafeteria had 23 apples. If they used 2...   \n",
       "\n",
       "                                         llm_message  \n",
       "0  The cafeteria had 23 apples to begin with. The...  \n",
       "1                        A: The answer is 29 apples.  \n",
       "2  A: The cafeteria started with 23 apples. They ...  "
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "minigpt4_inference_data_df = pd.DataFrame(minigpt4_inference_data)\n",
    "minigpt4_inference_data_df.to_csv('minigpt4_inference_data.csv')\n",
    "minigpt4_inference_data_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "facbcec6-5ae9-4556-bbfe-c39255abaf6b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "environment": {
   "kernel": "python3",
   "name": "pytorch-gpu.1-13.m109",
   "type": "gcloud",
   "uri": "gcr.io/deeplearning-platform-release/pytorch-gpu.1-13:m109"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
